"""Grade previously generated QA answers using the IDUN chat completions API.

Input: `results/*.json` generated by `evaluate.py`.
Output:
  - Updates each JSON file in-place by adding a `grade` key per item (T/F).
  - Writes/updates a matching `results/<stem>.log` with accuracy statistics.

Environment:
  - `IDUN_API_KEY` must be set (or use `--api-key`).
"""

from __future__ import annotations

import argparse
import json
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Any

import requests
from dotenv import load_dotenv


DEFAULT_GRADER_MODEL = "openai/gpt-oss-120b"
IDUN_API_URL = "https://idun-llm.hpc.ntnu.no/api/chat/completions"

GRADER_PROMPT = (
    "You are an expert in grading history quizzes using only knowledge from up to 1940.\n"
    "Given a question, a test answer, and the correct answer, output T if the test answer is "
    "essentially correct, or F if it is wrong. OUTPUT EXACTLY 1 CHARACTER AND NOTHING ELSE. "
    "Example: question: What's the capital of Egypt? Model Answer: Paris Correct answer: Cairo Output: F"
)


def build_argparser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Grade results/*.json files and write accuracy to matching .log")
    parser.add_argument("--out-dir", type=Path, default=Path(os.getenv("OUT_DIR", "results")))
    parser.add_argument("--api-key", default=os.getenv("IDUN_API_KEY"), help="IDUN API key (or set IDUN_API_KEY)")
    parser.add_argument("--grader-model", default=os.getenv("GRADER_MODEL", DEFAULT_GRADER_MODEL))
    parser.add_argument("--max-workers", type=int, default=int(os.getenv("MAX_WORKERS", "100")))
    parser.add_argument("--timeout-s", type=float, default=60.0)
    parser.add_argument("--dry-run", action="store_true", help="Do not write files; just report")
    return parser


def _load_json(path: Path) -> Any:
    raw = path.read_text(encoding="utf-8")
    if not raw.strip():
        raise ValueError("empty json")
    return json.loads(raw)


def _atomic_write_json(path: Path, data: Any) -> None:
    tmp_path = path.with_suffix(path.suffix + ".tmp")
    tmp_path.write_text(json.dumps(data, indent=2, ensure_ascii=False) + "\n", encoding="utf-8")
    tmp_path.replace(path)


def chat_with_model(*, api_key: str, model: str, user_content: str, timeout_s: float) -> dict[str, Any]:
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": GRADER_PROMPT},
            {"role": "user", "content": user_content},
        ],
    }
    resp = requests.post(IDUN_API_URL, headers=headers, json=payload, timeout=timeout_s)
    return resp.json()


def grade_single_answer(
    ans: dict[str, Any],
    *,
    api_key: str,
    grader_model: str,
    timeout_s: float,
) -> tuple[str, bool]:
    """Return (grade, is_invalid) for one answer item."""

    existing = str(ans.get("grade", "")).strip().upper()
    if existing in {"T", "F"}:
        return existing, False

    question_num = ans.get("question_num", "?")
    question = str(ans.get("question", ""))
    model_ans = str(ans.get("model_ans", ""))
    correct_ans = str(ans.get("correct_ans", ""))

    g = chat_with_model(
        api_key=api_key,
        model=grader_model,
        user_content=f"question: {question} model answer: {model_ans} Correct answer: {correct_ans}",
        timeout_s=timeout_s,
    )

    if "choices" not in g or not g.get("choices"):
        err = g.get("error", "Unknown")
        raise RuntimeError(f"invalid API response on Q{question_num}: {err}")

    content = str(g["choices"][0]["message"].get("content", "")).strip()
    grade = content[:1].upper() if content else "F"
    is_invalid = grade not in {"T", "F"}
    if is_invalid:
        # Normalize anything unexpected to F, but count it separately.
        grade = "F"
    return grade, is_invalid


def grade_file(
    json_path: Path,
    *,
    api_key: str,
    grader_model: str,
    timeout_s: float,
    max_workers: int,
    dry_run: bool,
) -> None:
    stem = json_path.stem
    logfile_path = json_path.with_suffix(".log")

    model_output = _load_json(json_path)
    if not isinstance(model_output, list):
        raise ValueError("expected a list of QA results")

    num_q = len(model_output)
    correct_answers = 0
    invalid_answers = 0

    start_ts = time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"Grading {num_q} questions from {stem} with {max_workers} workers... {start_ts}", flush=True)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(
                grade_single_answer,
                item,
                api_key=api_key,
                grader_model=grader_model,
                timeout_s=timeout_s,
            ): idx
            for idx, item in enumerate(model_output)
        }

        for future in as_completed(futures):
            idx = futures[future]
            try:
                grade, is_invalid = future.result()
            except Exception as exc:
                print(f"  Error grading Q{model_output[idx].get('question_num', '?')}: {exc}", file=sys.stderr)
                grade, is_invalid = "F", True

            model_output[idx]["grade"] = grade
            if grade == "T":
                correct_answers += 1
            if is_invalid:
                invalid_answers += 1

    accuracy = correct_answers / num_q if num_q > 0 else 0.0

    log_data: dict[str, Any] = {}
    if logfile_path.exists():
        try:
            existing = _load_json(logfile_path)
            if isinstance(existing, dict):
                log_data.update(existing)
        except Exception:
            pass

    log_data.update(
        {
            "correct_answers": correct_answers,
            "invalid_answers": invalid_answers,
            "accuracy": accuracy,
            "num_q": num_q,
        }
    )

    if dry_run:
        print(f"dry-run: would write {json_path.name} and {logfile_path.name}")
        return

    _atomic_write_json(logfile_path, log_data)
    _atomic_write_json(json_path, model_output)


def main() -> int:
    load_dotenv()
    args = build_argparser().parse_args()
    out_dir: Path = args.out_dir
    api_key: str | None = args.api_key
    if not api_key:
        raise SystemExit("IDUN API key missing. Set IDUN_API_KEY or pass --api-key")
    out_dir.mkdir(parents=True, exist_ok=True)

    json_files = sorted(out_dir.glob("*.json"))
    if not json_files:
        print(f"no .json files found under {out_dir}")
        return 0

    for p in json_files:
        try:
            grade_file(
                p,
                api_key=api_key,
                grader_model=str(args.grader_model),
                timeout_s=float(args.timeout_s),
                max_workers=int(args.max_workers),
                dry_run=bool(args.dry_run),
            )
        except Exception as exc:
            print(f"warn: failed to process {p.name}: {exc}", file=sys.stderr)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
